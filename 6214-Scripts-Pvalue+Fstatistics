




#Prepare the data

library(MASS)
data(Boston)
head(Boston)

#a brief introduction

#right model, everyone think
Model1 <- lm(medv~lstat+rm-1,data=Boston)
summary(Model1)


#you will find it incredibly significant
# SO above is the lr
#R -squared amount of noise
#if you believe it is normalization
#F test is more precise, generate pvale

Model2 <- lm(medv~lstat+rm+age+indus,data=Boston)
summary(Model2)


#compare MOdel2 and MOdel 1 ,coefficients changed

# if you add p-value

#focus on F statistic, 

#let's test 
#H_0: beta_age = beta_indus=0
#easily do that with F test

rss1 <- sum(residuals(Model1)^2) # = Model1$residuals
rss2 <- sum(residuals(Model2)^2)
#initialize
p1 <- 3 #number of vars in Model1
p2 <- 4 #number of vars in Model2
n <- nrow(Boston)#sample size
#from F definition
F_stat_num <- (rss1-rss2)/(p2-p1)
F_stat_denom <- rss1/(n-p1)
F_stat <- F_stat_num/F_stat_denom

#and add df
df_num <- p2-p1
df_denom <- n- p1

x.seq <- seq(from=0,to=10,length.out=1001 )
##check photo
plot(x.seq,df(x.seq,df1=df_num,df2=df_denom)
     #,type='1'
     )
#polygon(x=c(x.seq[x.seq >= F_stat],F_stat),
#        y=c(df(x.seq,df1=df_num,df2=df_denom))
#        )

#give you the cdf
pf(F_stat,df1=df_denom,df2=df_num)
F_stat_pvalue <- 1-pf(F_stat,df1=df_denom,df2=df_num)

F_stat_pvalue

##considering we get 0.097... Fstatistics, so we thinks Model1 is better?

#question?

#another function
alpha <- 0.05
qf(1-alpha,df1=df_num,df2=df_denom)

#a simple question for Fstatistics
anova(Model1,Model2)
Model_anova_12 <- anova(Model1,Model2)
str(Model_anova_12)

#and those are for normalization distribution,
#residuals are indepent...
#and if you decide to take the results you get follow this way,
#
#you have to prove it ,by the following ways:
#plot(Model1)
#first image is weird, because it supposed to be flat,but the left part is higher
#second image is weird,because QQ plot is not based on the line,some of the residuals is not normal
##and heavy tail? and what?
#third image ?Scale location?


plot(x=Boston$lstat,y=Boston$medv)
abline(lm(medv~lstat,data=Boston),col=2,lwd=3)
#we see a straight line here, and it shows we have to do a transformation
newLm <- lm(medv~log(lstat),data=Boston)
##plot the log,and found the right part seems better
##
plot(x=Boston$lstat,y=Boston$medv)
abline(lm(medv~lstat,data=Boston),col=2,lwd=3)

#if we change it a little more, then it becomes even better
Model1A <- lm(medv~log(lstat)+rm,data=Boston)
##plot(Model1A)
Model2A <- lm(medv~log(lstat)+rm+age+indus,data=Boston)
##plot

#question, should we do those transformation one by one? just try?
#let's check again the anova
anova(Model1A,Model2A)

#because the prediction improves, so the anova actually becomes better

##check the photo

#changing x ,makes the model much better
#what can we do if there are changing variant?

#question, what if the model is just that,
#lengthy
